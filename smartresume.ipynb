{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gLmr7F-_CJh",
        "outputId": "9825bf62-250d-4b07-fe1b-e00660159c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.19.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.7.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, PyPDF2, pydeck, streamlit\n",
            "Successfully installed PyPDF2-3.0.1 pydeck-0.9.1 python-docx-1.2.0 streamlit-1.50.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-15 17:51:00.789 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:00.791 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:00.994 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-10-15 17:51:00.995 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:00.997 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:00.998 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.000 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.001 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.003 Session state does not function when running a script without `streamlit run`\n",
            "2025-10-15 17:51:01.004 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.004 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.005 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.006 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.007 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.009 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.011 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.011 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.012 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.013 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.014 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.015 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.016 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.018 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.019 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.019 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.020 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.021 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.021 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.022 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.023 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.024 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.025 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.028 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.029 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.029 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.030 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.032 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.034 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.035 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.036 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.036 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.037 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.038 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.039 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.040 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-15 17:51:01.040 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "# Smart Resume Screener - Collaborative Code\n",
        "# Install required packages first:\n",
        "!pip install streamlit PyPDF2 python-docx spacy scikit-learn plotly\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "import streamlit as st\n",
        "import PyPDF2\n",
        "import docx\n",
        "import re\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "import io\n",
        "\n",
        "# Initialize spaCy for NLP\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    st.error(\"Please download the spaCy model: python -m spacy download en_core_web_sm\")\n",
        "    st.stop()\n",
        "\n",
        "class ResumeScreener:\n",
        "    def __init__(self):\n",
        "        self.skills_keywords = [\n",
        "            'python', 'java', 'javascript', 'sql', 'html', 'css', 'react', 'node.js',\n",
        "            'machine learning', 'deep learning', 'tensorflow', 'pytorch', 'aws',\n",
        "            'docker', 'kubernetes', 'git', 'rest api', 'mongodb', 'mysql', 'postgresql',\n",
        "            'data analysis', 'pandas', 'numpy', 'tableau', 'power bi', 'excel',\n",
        "            'project management', 'agile', 'scrum', 'leadership', 'communication',\n",
        "            'problem solving', 'teamwork', 'analytical skills'\n",
        "        ]\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_file):\n",
        "        \"\"\"Extract text from PDF file\"\"\"\n",
        "        try:\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error reading PDF: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_text_from_docx(self, docx_file):\n",
        "        \"\"\"Extract text from DOCX file\"\"\"\n",
        "        try:\n",
        "            doc = docx.Document(docx_file)\n",
        "            text = \"\"\n",
        "            for paragraph in doc.paragraphs:\n",
        "                text += paragraph.text + \"\\n\"\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error reading DOCX: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_skills(self, text):\n",
        "        \"\"\"Extract skills from resume text\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        found_skills = []\n",
        "\n",
        "        for skill in self.skills_keywords:\n",
        "            if skill in text_lower:\n",
        "                found_skills.append(skill)\n",
        "\n",
        "        # Use spaCy for additional skill extraction\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ in [\"ORG\", \"PRODUCT\", \"TECH\"]:\n",
        "                if ent.text.lower() not in found_skills and len(ent.text) > 2:\n",
        "                    found_skills.append(ent.text.lower())\n",
        "\n",
        "        return list(set(found_skills))\n",
        "\n",
        "    def extract_experience(self, text):\n",
        "        \"\"\"Extract experience information\"\"\"\n",
        "        # Look for years of experience patterns\n",
        "        experience_patterns = [\n",
        "            r'(\\d+)\\+?\\s*years?',\n",
        "            r'experience.*?(\\d+)\\+?\\s*years?',\n",
        "            r'(\\d+)\\+?\\s*years?.*?experience'\n",
        "        ]\n",
        "\n",
        "        years = []\n",
        "        for pattern in experience_patterns:\n",
        "            matches = re.finditer(pattern, text.lower())\n",
        "            for match in matches:\n",
        "                try:\n",
        "                    years.append(int(match.group(1)))\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        return max(years) if years else 0\n",
        "\n",
        "    def extract_education(self, text):\n",
        "        \"\"\"Extract education information\"\"\"\n",
        "        education_keywords = [\n",
        "            'bachelor', 'master', 'phd', 'mba', 'bs', 'ms', 'ba', 'ma',\n",
        "            'university', 'college', 'degree', 'graduated'\n",
        "        ]\n",
        "\n",
        "        text_lower = text.lower()\n",
        "        education_info = []\n",
        "\n",
        "        for keyword in education_keywords:\n",
        "            if keyword in text_lower:\n",
        "                # Extract context around the keyword\n",
        "                start = max(0, text_lower.find(keyword) - 50)\n",
        "                end = min(len(text_lower), text_lower.find(keyword) + 50)\n",
        "                context = text[start:end].strip()\n",
        "                education_info.append(context)\n",
        "\n",
        "        return education_info\n",
        "\n",
        "    def calculate_match_score(self, resume_text, job_description):\n",
        "        \"\"\"Calculate match score between resume and job description\"\"\"\n",
        "        # TF-IDF based similarity\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        corpus = [resume_text, job_description]\n",
        "        tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "\n",
        "        # Skills matching bonus\n",
        "        resume_skills = self.extract_skills(resume_text)\n",
        "        jd_skills = self.extract_skills(job_description)\n",
        "\n",
        "        if jd_skills:\n",
        "            skills_match_ratio = len(set(resume_skills) & set(jd_skills)) / len(jd_skills)\n",
        "        else:\n",
        "            skills_match_ratio = 0\n",
        "\n",
        "        # Combine scores\n",
        "        final_score = (similarity[0][0] * 0.6) + (skills_match_ratio * 0.4)\n",
        "\n",
        "        return min(final_score * 10, 10), resume_skills, jd_skills\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"Smart Resume Screener\", page_icon=\"📄\", layout=\"wide\")\n",
        "\n",
        "    st.title(\"🤖 Smart Resume Screener\")\n",
        "    st.markdown(\"Upload resumes and job descriptions to find the best matches!\")\n",
        "\n",
        "    # Initialize session state\n",
        "    if 'resumes' not in st.session_state:\n",
        "        st.session_state.resumes = []\n",
        "    if 'job_description' not in st.session_state:\n",
        "        st.session_state.job_description = \"\"\n",
        "\n",
        "    # Initialize screener\n",
        "    screener = ResumeScreener()\n",
        "\n",
        "    # Sidebar for job description\n",
        "    with st.sidebar:\n",
        "        st.header(\"Job Description\")\n",
        "        job_description = st.text_area(\n",
        "            \"Paste the job description here:\",\n",
        "            height=300,\n",
        "            value=st.session_state.job_description,\n",
        "            help=\"Enter the complete job description for matching\"\n",
        "        )\n",
        "\n",
        "        st.session_state.job_description = job_description\n",
        "\n",
        "        st.header(\"Upload Resumes\")\n",
        "        uploaded_files = st.file_uploader(\n",
        "            \"Choose resume files (PDF/DOCX)\",\n",
        "            type=['pdf', 'docx'],\n",
        "            accept_multiple_files=True,\n",
        "            help=\"Upload multiple resumes in PDF or DOCX format\"\n",
        "        )\n",
        "\n",
        "    # Main content area\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        if uploaded_files and job_description:\n",
        "            st.subheader(\"📊 Resume Analysis Results\")\n",
        "\n",
        "            results = []\n",
        "            for uploaded_file in uploaded_files:\n",
        "                # Extract text based on file type\n",
        "                if uploaded_file.type == \"application/pdf\":\n",
        "                    text = screener.extract_text_from_pdf(uploaded_file)\n",
        "                elif uploaded_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "                    text = screener.extract_text_from_docx(uploaded_file)\n",
        "                else:\n",
        "                    text = \"\"\n",
        "\n",
        "                if text:\n",
        "                    # Analyze resume\n",
        "                    skills = screener.extract_skills(text)\n",
        "                    experience = screener.extract_experience(text)\n",
        "                    education = screener.extract_education(text)\n",
        "                    match_score, resume_skills, jd_skills = screener.calculate_match_score(text, job_description)\n",
        "\n",
        "                    results.append({\n",
        "                        'filename': uploaded_file.name,\n",
        "                        'match_score': match_score,\n",
        "                        'skills': skills,\n",
        "                        'experience_years': experience,\n",
        "                        'education_snippets': education,\n",
        "                        'resume_skills': resume_skills,\n",
        "                        'jd_skills': jd_skills,\n",
        "                        'text': text[:500] + \"...\"  # Store first 500 chars for preview\n",
        "                    })\n",
        "\n",
        "            # Sort results by match score\n",
        "            results.sort(key=lambda x: x['match_score'], reverse=True)\n",
        "\n",
        "            # Display results\n",
        "            for result in results:\n",
        "                with st.expander(f\"📄 {result['filename']} - Score: {result['match_score']:.1f}/10\", expanded=False):\n",
        "                    col_a, col_b, col_c = st.columns(3)\n",
        "\n",
        "                    with col_a:\n",
        "                        st.metric(\"Match Score\", f\"{result['match_score']:.1f}/10\")\n",
        "\n",
        "                    with col_b:\n",
        "                        st.metric(\"Skills Found\", len(result['skills']))\n",
        "\n",
        "                    with col_c:\n",
        "                        st.metric(\"Experience\", f\"{result['experience_years']} years\")\n",
        "\n",
        "                    # Skills analysis\n",
        "                    st.subheader(\"🔧 Skills Analysis\")\n",
        "                    matched_skills = set(result['resume_skills']) & set(result['jd_skills'])\n",
        "                    missing_skills = set(result['jd_skills']) - set(result['resume_skills'])\n",
        "\n",
        "                    col_skills1, col_skills2 = st.columns(2)\n",
        "\n",
        "                    with col_skills1:\n",
        "                        st.write(\"✅ **Matched Skills:**\")\n",
        "                        if matched_skills:\n",
        "                            for skill in list(matched_skills)[:10]:  # Show first 10\n",
        "                                st.write(f\"- {skill}\")\n",
        "                        else:\n",
        "                            st.write(\"No matching skills found\")\n",
        "\n",
        "                    with col_skills2:\n",
        "                        st.write(\"❌ **Missing Skills:**\")\n",
        "                        if missing_skills:\n",
        "                            for skill in list(missing_skills)[:10]:  # Show first 10\n",
        "                                st.write(f\"- {skill}\")\n",
        "                        else:\n",
        "                            st.write(\"All required skills matched!\")\n",
        "\n",
        "                    # Education preview\n",
        "                    if result['education_snippets']:\n",
        "                        st.subheader(\"🎓 Education Highlights\")\n",
        "                        for edu in result['education_snippets'][:3]:  # Show first 3\n",
        "                            st.write(f\"- {edu}\")\n",
        "\n",
        "                    # Resume preview\n",
        "                    st.subheader(\"📋 Resume Preview\")\n",
        "                    st.text_area(\n",
        "                        \"First 500 characters:\",\n",
        "                        value=result['text'],\n",
        "                        height=100,\n",
        "                        key=f\"preview_{result['filename']}\"\n",
        "                    )\n",
        "\n",
        "            # Create summary dataframe\n",
        "            if results:\n",
        "                df_results = pd.DataFrame([{\n",
        "                    'Filename': r['filename'],\n",
        "                    'Match Score': r['match_score'],\n",
        "                    'Skills Count': len(r['skills']),\n",
        "                    'Experience (Years)': r['experience_years']\n",
        "                } for r in results])\n",
        "\n",
        "                st.subheader(\"📈 Summary Dashboard\")\n",
        "\n",
        "                # Visualization\n",
        "                fig = px.bar(\n",
        "                    df_results,\n",
        "                    x='Filename',\n",
        "                    y='Match Score',\n",
        "                    title='Resume Match Scores',\n",
        "                    color='Match Score',\n",
        "                    color_continuous_scale='viridis'\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                # Download results\n",
        "                csv = df_results.to_csv(index=False)\n",
        "                st.download_button(\n",
        "                    label=\"📥 Download Results as CSV\",\n",
        "                    data=csv,\n",
        "                    file_name=f\"resume_screening_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                    mime=\"text/csv\"\n",
        "                )\n",
        "\n",
        "        elif uploaded_files and not job_description:\n",
        "            st.warning(\"⚠️ Please enter a job description to analyze resumes.\")\n",
        "        elif not uploaded_files and job_description:\n",
        "            st.info(\"📁 Please upload resume files to analyze.\")\n",
        "        else:\n",
        "            st.info(\"👈 Please upload resumes and enter a job description to get started.\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"ℹ️ How to Use\")\n",
        "        st.markdown(\"\"\"\n",
        "        1. **Enter Job Description** in the sidebar\n",
        "        2. **Upload Resumes** (PDF/DOCX format)\n",
        "        3. **View Analysis** including:\n",
        "           - Match score (1-10)\n",
        "           - Skills matching\n",
        "           - Experience extraction\n",
        "           - Education highlights\n",
        "\n",
        "        **Features:**\n",
        "        - 📊 Smart scoring algorithm\n",
        "        - 🔧 Skills gap analysis\n",
        "        - 📈 Visual comparisons\n",
        "        - 📥 Export results\n",
        "        \"\"\")\n",
        "\n",
        "        if job_description:\n",
        "            st.subheader(\"📋 Job Description Analysis\")\n",
        "            jd_skills = screener.extract_skills(job_description)\n",
        "            st.write(f\"**Required Skills Found:** {len(jd_skills)}\")\n",
        "            if jd_skills:\n",
        "                for skill in jd_skills[:15]:  # Show first 15 skills\n",
        "                    st.write(f\"- {skill}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced version with LLM capabilities\n",
        "# !pip install openai anthropic\n",
        "\n",
        "import openai\n",
        "import json\n",
        "\n",
        "class EnhancedResumeScreener(ResumeScreener):\n",
        "    def __init__(self, api_key=None):\n",
        "        super().__init__()\n",
        "        if api_key:\n",
        "            openai.api_key = api_key\n",
        "\n",
        "    def llm_enhanced_analysis(self, resume_text, job_description, resume_skills, jd_skills):\n",
        "        \"\"\"Use LLM for enhanced analysis and justification\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        Analyze the following resume against the job description and provide:\n",
        "        1. Overall match score (1-10)\n",
        "        2. Key strengths\n",
        "        3. Areas for improvement\n",
        "        4. Detailed justification\n",
        "\n",
        "        Resume Skills: {', '.join(resume_skills)}\n",
        "        Job Required Skills: {', '.join(jd_skills)}\n",
        "\n",
        "        Resume Excerpt: {resume_text[:1500]}\n",
        "        Job Description: {job_description[:1000]}\n",
        "\n",
        "        Provide response in JSON format:\n",
        "        {{\n",
        "            \"match_score\": 0,\n",
        "            \"strengths\": [],\n",
        "            \"improvements\": [],\n",
        "            \"justification\": \"\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert HR analyst. Provide detailed, objective analysis.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.3\n",
        "            )\n",
        "\n",
        "            analysis = json.loads(response.choices[0].message.content)\n",
        "            return analysis\n",
        "        except Exception as e:\n",
        "            # Fallback to basic analysis\n",
        "            return {\n",
        "                \"match_score\": 0,\n",
        "                \"strengths\": [\"Basic skills matching available\"],\n",
        "                \"improvements\": [\"Enable LLM for detailed analysis\"],\n",
        "                \"justification\": \"LLM analysis not available\"\n",
        "            }\n",
        "\n",
        "# Add this to your main function after the basic analysis\n",
        "def enhanced_main():\n",
        "    # Add LLM API key input in sidebar\n",
        "    with st.sidebar:\n",
        "        st.header(\"🤖 Advanced Features\")\n",
        "        api_key = st.text_input(\"OpenAI API Key (optional)\", type=\"password\")\n",
        "        use_llm = st.checkbox(\"Enable AI Analysis\")\n",
        "\n",
        "    # In the analysis section, add:\n",
        "    if use_llm and api_key:\n",
        "        enhanced_screener = EnhancedResumeScreener(api_key)\n",
        "        for result in results:\n",
        "            llm_analysis = enhanced_screener.llm_enhanced_analysis(\n",
        "                result['text'],\n",
        "                job_description,\n",
        "                result['resume_skills'],\n",
        "                result['jd_skills']\n",
        "            )\n",
        "            result['llm_analysis'] = llm_analysis\n",
        "\n",
        "            # Display LLM analysis in expander\n",
        "            with st.expander(\"🤖 AI Analysis\", expanded=False):\n",
        "                st.metric(\"AI Match Score\", f\"{llm_analysis['match_score']}/10\")\n",
        "                st.write(\"**Strengths:**\")\n",
        "                for strength in llm_analysis['strengths']:\n",
        "                    st.write(f\"✅ {strength}\")\n",
        "                st.write(\"**Improvements:**\")\n",
        "                for improvement in llm_analysis['improvements']:\n",
        "                    st.write(f\"📝 {improvement}\")\n",
        "                st.write(\"**Justification:**\")\n",
        "                st.write(llm_analysis['justification'])"
      ],
      "metadata": {
        "id": "CgUxo9z-_p28"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Database support for storing results\n",
        "# !pip install sqlalchemy\n",
        "\n",
        "from sqlalchemy import create_engine, Column, String, Integer, Float, DateTime, Text\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import sqlite3\n",
        "\n",
        "Base = declarative_base()\n",
        "\n",
        "class ResumeAnalysis(Base):\n",
        "    __tablename__ = 'resume_analyses'\n",
        "\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    filename = Column(String)\n",
        "    match_score = Column(Float)\n",
        "    skills_found = Column(Integer)\n",
        "    experience_years = Column(Integer)\n",
        "    analysis_date = Column(DateTime)\n",
        "    job_description_hash = Column(String)\n",
        "    resume_text_preview = Column(Text)\n",
        "\n",
        "class DatabaseManager:\n",
        "    def __init__(self, db_url=\"sqlite:///resume_analyses.db\"):\n",
        "        self.engine = create_engine(db_url)\n",
        "        Base.metadata.create_all(self.engine)\n",
        "        Session = sessionmaker(bind=self.engine)\n",
        "        self.session = Session()\n",
        "\n",
        "    def save_analysis(self, result, job_description):\n",
        "        analysis = ResumeAnalysis(\n",
        "            filename=result['filename'],\n",
        "            match_score=result['match_score'],\n",
        "            skills_found=len(result['skills']),\n",
        "            experience_years=result['experience_years'],\n",
        "            analysis_date=datetime.now(),\n",
        "            job_description_hash=hash(job_description),\n",
        "            resume_text_preview=result['text']\n",
        "        )\n",
        "        self.session.add(analysis)\n",
        "        self.session.commit()\n",
        "\n",
        "    def get_analysis_history(self):\n",
        "        return self.session.query(ResumeAnalysis).all()\n",
        "\n",
        "# Add to main function\n",
        "def main_with_db():\n",
        "    db_manager = DatabaseManager()\n",
        "\n",
        "    # After analysis, save to database\n",
        "    for result in results:\n",
        "        db_manager.save_analysis(result, job_description)\n",
        "\n",
        "    # Add history view in sidebar\n",
        "    with st.sidebar:\n",
        "        if st.button(\"View Analysis History\"):\n",
        "            history = db_manager.get_analysis_history()\n",
        "            if history:\n",
        "                st.subheader(\"📊 Analysis History\")\n",
        "                for analysis in history[-5:]:  # Last 5 analyses\n",
        "                    st.write(f\"{analysis.filename}: {analysis.match_score:.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpYQfsixAvNr",
        "outputId": "264d7b2d-4955-4163-cf86-3f4727e2a8ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3156571352.py:9: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced skills matching with categories\n",
        "class AdvancedResumeScreener(ResumeScreener):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.skills_categories = {\n",
        "            'programming': ['python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'go', 'rust'],\n",
        "            'web_dev': ['html', 'css', 'react', 'angular', 'vue', 'node.js', 'django', 'flask'],\n",
        "            'databases': ['sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'oracle'],\n",
        "            'cloud': ['aws', 'azure', 'gcp', 'docker', 'kubernetes', 'terraform'],\n",
        "            'data_science': ['pandas', 'numpy', 'tensorflow', 'pytorch', 'scikit-learn', 'r'],\n",
        "            'tools': ['git', 'jenkins', 'jira', 'confluence', 'slack'],\n",
        "            'soft_skills': ['leadership', 'communication', 'teamwork', 'problem solving']\n",
        "        }\n",
        "\n",
        "    def categorize_skills(self, skills):\n",
        "        categorized = {category: [] for category in self.skills_categories.keys()}\n",
        "        categorized['other'] = []\n",
        "\n",
        "        for skill in skills:\n",
        "            found = False\n",
        "            for category, category_skills in self.skills_categories.items():\n",
        "                if skill in category_skills:\n",
        "                    categorized[category].append(skill)\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                categorized['other'].append(skill)\n",
        "\n",
        "        return categorized\n",
        "\n",
        "    def calculate_advanced_match_score(self, resume_text, job_description):\n",
        "        base_score, resume_skills, jd_skills = self.calculate_match_score(resume_text, job_description)\n",
        "\n",
        "        # Category-based scoring\n",
        "        resume_categories = self.categorize_skills(resume_skills)\n",
        "        jd_categories = self.categorize_skills(jd_skills)\n",
        "\n",
        "        category_bonus = 0\n",
        "        for category in jd_categories:\n",
        "            if jd_categories[category] and resume_categories[category]:\n",
        "                category_match = len(set(resume_categories[category]) & set(jd_categories[category])) / len(jd_categories[category])\n",
        "                category_bonus += category_match * 0.5  # Bonus for category coverage\n",
        "\n",
        "        final_score = min(base_score + category_bonus, 10)\n",
        "        return final_score, resume_categories, jd_categories\n",
        "\n",
        "# Add to your display section\n",
        "def display_skill_categories(resume_categories, jd_categories):\n",
        "    st.subheader(\"📊 Skills by Category\")\n",
        "\n",
        "    for category in resume_categories:\n",
        "        if resume_categories[category] or jd_categories[category]:\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.write(f\"**{category.title()}**\")\n",
        "                if resume_categories[category]:\n",
        "                    for skill in resume_categories[category]:\n",
        "                        st.write(f\"✅ {skill}\")\n",
        "                else:\n",
        "                    st.write(\"No skills found\")\n",
        "\n",
        "            with col2:\n",
        "                st.write(\"**Required**\")\n",
        "                if jd_categories[category]:\n",
        "                    for skill in jd_categories[category]:\n",
        "                        if skill in resume_categories[category]:\n",
        "                            st.write(f\"✅ {skill}\")\n",
        "                        else:\n",
        "                            st.write(f\"❌ {skill}\")"
      ],
      "metadata": {
        "id": "YBgxn-XZAwN3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# requirements.txt for deployment\n",
        "\"\"\"\n",
        "streamlit==1.28.0\n",
        "PyPDF2==3.0.1\n",
        "python-docx==0.8.11\n",
        "spacy==3.7.0\n",
        "scikit-learn==1.3.0\n",
        "plotly==5.15.0\n",
        "pandas==2.1.0\n",
        "openai==0.28.0\n",
        "sqlalchemy==2.0.20\n",
        "\"\"\"\n",
        "\n",
        "# .streamlit/config.toml\n",
        "\"\"\"\n",
        "[theme]\n",
        "primaryColor = \"#FF4B4B\"\n",
        "backgroundColor = \"#FFFFFF\"\n",
        "secondaryBackgroundColor = \"#F0F2F6\"\n",
        "textColor = \"#262730\"\n",
        "font = \"sans serif\"\n",
        "\n",
        "[server]\n",
        "headless = true\n",
        "port = 8501\n",
        "enableCORS = false\n",
        "\"\"\"\n",
        "\n",
        "# Dockerfile for container deployment\n",
        "\"\"\"\n",
        "FROM python:3.9-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "COPY requirements.txt .\n",
        "RUN pip install -r requirements.txt\n",
        "RUN python -m spacy download en_core_web_sm\n",
        "\n",
        "COPY . .\n",
        "\n",
        "EXPOSE 8501\n",
        "\n",
        "HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health\n",
        "\n",
        "ENTRYPOINT [\"streamlit\", \"run\", \"resume_screener.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nS36J3aJAz88",
        "outputId": "ae8f7e96-543f-4e95-ca76-b98cff60d125"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFROM python:3.9-slim\\n\\nWORKDIR /app\\n\\nCOPY requirements.txt .\\nRUN pip install -r requirements.txt\\nRUN python -m spacy download en_core_web_sm\\n\\nCOPY . .\\n\\nEXPOSE 8501\\n\\nHEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health\\n\\nENTRYPOINT [\"streamlit\", \"run\", \"resume_screener.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit tests for the resume screener - Colab Compatible Version\n",
        "import unittest\n",
        "import sys\n",
        "import io\n",
        "\n",
        "class TestResumeScreener(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.screener = ResumeScreener()\n",
        "\n",
        "    def test_skills_extraction(self):\n",
        "        test_text = \"I have experience with Python, JavaScript, and AWS.\"\n",
        "        skills = self.screener.extract_skills(test_text)\n",
        "        self.assertIn('python', skills)\n",
        "        self.assertIn('javascript', skills)\n",
        "        self.assertIn('aws', skills)\n",
        "        print(\"✅ Skills extraction test passed\")\n",
        "\n",
        "    def test_experience_extraction(self):\n",
        "        test_text = \"I have 5 years of experience in software development.\"\n",
        "        experience = self.screener.extract_experience(test_text)\n",
        "        self.assertEqual(experience, 5)\n",
        "        print(\"✅ Experience extraction test passed\")\n",
        "\n",
        "    def test_experience_extraction_multiple(self):\n",
        "        test_text = \"3 years as intern and 2 years as full-time developer with total 5 years experience.\"\n",
        "        experience = self.screener.extract_experience(test_text)\n",
        "        self.assertEqual(experience, 5)\n",
        "        print(\"✅ Multiple experience extraction test passed\")\n",
        "\n",
        "    def test_education_extraction(self):\n",
        "        test_text = \"I have a Bachelor's degree in Computer Science from University of Test.\"\n",
        "        education = self.screener.extract_education(test_text)\n",
        "        self.assertTrue(len(education) > 0)\n",
        "        self.assertTrue(any('bachelor' in edu.lower() for edu in education))\n",
        "        print(\"✅ Education extraction test passed\")\n",
        "\n",
        "    def test_match_score_calculation(self):\n",
        "        resume_text = \"Expert in Python and SQL with database management skills.\"\n",
        "        job_description = \"We need Python developers with SQL experience for database projects.\"\n",
        "        score, resume_skills, jd_skills = self.screener.calculate_match_score(resume_text, job_description)\n",
        "        self.assertGreaterEqual(score, 0)\n",
        "        self.assertLessEqual(score, 10)\n",
        "        self.assertIn('python', resume_skills)\n",
        "        self.assertIn('sql', resume_skills)\n",
        "        print(\"✅ Match score calculation test passed\")\n",
        "\n",
        "    def test_pdf_text_extraction(self):\n",
        "        # Create a simple PDF in memory for testing\n",
        "        from PyPDF2 import PdfWriter, PdfReader\n",
        "        import io\n",
        "\n",
        "        # Create a PDF in memory\n",
        "        pdf_writer = PdfWriter()\n",
        "        pdf_writer.add_blank_page(width=200, height=200)\n",
        "\n",
        "        # Add some text (this is simplified for testing)\n",
        "        output = io.BytesIO()\n",
        "        pdf_writer.write(output)\n",
        "        output.seek(0)\n",
        "\n",
        "        # Try to extract text (will be empty for blank page, but shouldn't crash)\n",
        "        text = self.screener.extract_text_from_pdf(output)\n",
        "        self.assertIsInstance(text, str)\n",
        "        print(\"✅ PDF text extraction test passed\")\n",
        "\n",
        "    def test_skills_keywords_presence(self):\n",
        "        self.assertGreater(len(self.screener.skills_keywords), 0)\n",
        "        self.assertIn('python', self.screener.skills_keywords)\n",
        "        self.assertIn('machine learning', self.screener.skills_keywords)\n",
        "        print(\"✅ Skills keywords test passed\")\n",
        "\n",
        "# Function to run tests in Colab\n",
        "def run_resume_screener_tests():\n",
        "    \"\"\"Run all tests and display results\"\"\"\n",
        "    print(\"🧪 Running Resume Screener Tests...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Create test suite\n",
        "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestResumeScreener)\n",
        "\n",
        "    # Capture test output\n",
        "    test_runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)\n",
        "\n",
        "    # Run tests\n",
        "    result = test_runner.run(test_suite)\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    if result.wasSuccessful():\n",
        "        print(\"🎉 All tests passed!\")\n",
        "    else:\n",
        "        print(f\"❌ {len(result.failures)} tests failed, {len(result.errors)} errors\")\n",
        "\n",
        "    return result\n",
        "\n",
        "# Run the tests\n",
        "run_resume_screener_tests()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdFLqup6BFeO",
        "outputId": "62ec3674-410a-4fd2-a734-0eba12473b7c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Running Resume Screener Tests...\n",
            "==================================================\n",
            "test_education_extraction (__main__.TestResumeScreener.test_education_extraction) ... ✅ Education extraction test passed\n",
            "ok\n",
            "test_experience_extraction (__main__.TestResumeScreener.test_experience_extraction) ... ✅ Experience extraction test passed\n",
            "ok\n",
            "test_experience_extraction_multiple (__main__.TestResumeScreener.test_experience_extraction_multiple) ... ✅ Multiple experience extraction test passed\n",
            "ok\n",
            "test_match_score_calculation (__main__.TestResumeScreener.test_match_score_calculation) ... ✅ Match score calculation test passed\n",
            "ok\n",
            "test_pdf_text_extraction (__main__.TestResumeScreener.test_pdf_text_extraction) ... ✅ PDF text extraction test passed\n",
            "ok\n",
            "test_skills_extraction (__main__.TestResumeScreener.test_skills_extraction) ... ✅ Skills extraction test passed\n",
            "ok\n",
            "test_skills_keywords_presence (__main__.TestResumeScreener.test_skills_keywords_presence) ... ✅ Skills keywords test passed\n",
            "ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 7 tests in 0.103s\n",
            "\n",
            "OK\n",
            "==================================================\n",
            "🎉 All tests passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=7 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For processing multiple resumes in batch\n",
        "def batch_process_resumes(folder_path, job_description):\n",
        "    \"\"\"Process all resumes in a folder\"\"\"\n",
        "    import os\n",
        "    screener = ResumeScreener()\n",
        "    results = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        if filename.endswith('.pdf'):\n",
        "            with open(file_path, 'rb') as f:\n",
        "                text = screener.extract_text_from_pdf(f)\n",
        "        elif filename.endswith('.docx'):\n",
        "            text = screener.extract_text_from_docx(file_path)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        if text:\n",
        "            match_score, resume_skills, jd_skills = screener.calculate_match_score(text, job_description)\n",
        "            results.append({\n",
        "                'filename': filename,\n",
        "                'match_score': match_score,\n",
        "                'skills': resume_skills\n",
        "            })\n",
        "\n",
        "    return sorted(results, key=lambda x: x['match_score'], reverse=True)"
      ],
      "metadata": {
        "id": "ZIV1XkuLBPHM"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}